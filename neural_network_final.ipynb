{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b06d38-4822-40f2-b1e6-888209417cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,MinMaxScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "# from keras.utils import plot_model\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1a60bc-befd-4ca8-b80d-5565473ae72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc2f24a0-44b2-478e-9a72-0d5301c240fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 50)                300       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,846\n",
      "Trainable params: 1,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "40/40 [==============================] - 1s 4ms/step - loss: 16278.9414 - val_loss: 111690.4922\n",
      "Epoch 2/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 15426.2129 - val_loss: 108091.6016\n",
      "Epoch 3/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 12615.2549 - val_loss: 97171.6328\n",
      "Epoch 4/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7323.6230 - val_loss: 74859.7812\n",
      "Epoch 5/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3346.1936 - val_loss: 50242.2461\n",
      "Epoch 6/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2031.4534 - val_loss: 34388.5000\n",
      "Epoch 7/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1440.8359 - val_loss: 23883.7949\n",
      "Epoch 8/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1039.7870 - val_loss: 17015.7871\n",
      "Epoch 9/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 763.8874 - val_loss: 12977.7168\n",
      "Epoch 10/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 582.4855 - val_loss: 10072.0742\n",
      "Epoch 11/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 453.5009 - val_loss: 8321.8926\n",
      "Epoch 12/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 362.5741 - val_loss: 7831.0981\n",
      "Epoch 13/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 302.7659 - val_loss: 7307.5869\n",
      "Epoch 14/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 259.5091 - val_loss: 7356.7310\n",
      "Epoch 15/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 227.1376 - val_loss: 7299.3052\n",
      "Epoch 16/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 202.0670 - val_loss: 7431.0488\n",
      "Epoch 17/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 183.4033 - val_loss: 7181.0039\n",
      "Epoch 18/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 167.9967 - val_loss: 7118.0806\n",
      "Epoch 19/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 156.2486 - val_loss: 7338.6895\n",
      "Epoch 20/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 145.3617 - val_loss: 7306.9985\n",
      "Epoch 21/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 138.5269 - val_loss: 7034.5391\n",
      "Epoch 22/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 130.9694 - val_loss: 6947.6973\n",
      "Epoch 23/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 124.6494 - val_loss: 7074.7124\n",
      "Epoch 24/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 118.7264 - val_loss: 7311.7188\n",
      "Epoch 25/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 118.3614 - val_loss: 6915.1221\n",
      "Epoch 26/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 109.8782 - val_loss: 6809.1206\n",
      "Epoch 27/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 105.1174 - val_loss: 6745.1768\n",
      "Epoch 28/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 103.0428 - val_loss: 6786.2358\n",
      "Epoch 29/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 97.2907 - val_loss: 6994.9395\n",
      "Epoch 30/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 93.4683 - val_loss: 6841.0576\n",
      "Epoch 31/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 90.5916 - val_loss: 6742.1909\n",
      "Epoch 32/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 89.1549 - val_loss: 6822.5713\n",
      "Epoch 33/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 84.8034 - val_loss: 6550.3013\n",
      "Epoch 34/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 82.9100 - val_loss: 6501.7383\n",
      "Epoch 35/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 80.2516 - val_loss: 6509.2603\n",
      "Epoch 36/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 78.5976 - val_loss: 6490.0166\n",
      "Epoch 37/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 77.3455 - val_loss: 6575.9717\n",
      "Epoch 38/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 74.2952 - val_loss: 6309.0991\n",
      "Epoch 39/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 72.3350 - val_loss: 6519.0957\n",
      "Epoch 40/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 70.5668 - val_loss: 6494.6860\n",
      "Epoch 41/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 69.1484 - val_loss: 6447.1704\n",
      "Epoch 42/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 68.8026 - val_loss: 6264.4824\n",
      "Epoch 43/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 67.4251 - val_loss: 6125.9800\n",
      "Epoch 44/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 66.9173 - val_loss: 6334.9106\n",
      "Epoch 45/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 63.1809 - val_loss: 6254.7832\n",
      "Epoch 46/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 63.8386 - val_loss: 6388.5283\n",
      "Epoch 47/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 61.1044 - val_loss: 6363.2305\n",
      "Epoch 48/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 59.6839 - val_loss: 6394.9907\n",
      "Epoch 49/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 58.9415 - val_loss: 6248.6475\n",
      "Epoch 50/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 58.2091 - val_loss: 6296.6904\n",
      "Epoch 51/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 56.4621 - val_loss: 6545.2217\n",
      "Epoch 52/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 55.6470 - val_loss: 6159.9023\n",
      "Epoch 53/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 55.5016 - val_loss: 6195.1685\n",
      "Epoch 54/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 55.8957 - val_loss: 6136.6919\n",
      "Epoch 55/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 52.5934 - val_loss: 6427.7339\n",
      "Epoch 56/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 52.9026 - val_loss: 6340.9375\n",
      "Epoch 57/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 57.9056 - val_loss: 5934.2300\n",
      "Epoch 58/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 50.6862 - val_loss: 6068.7837\n",
      "Epoch 59/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 50.1965 - val_loss: 6128.2627\n",
      "Epoch 60/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 49.4999 - val_loss: 6187.7676\n",
      "Epoch 61/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 49.2605 - val_loss: 6157.6758\n",
      "Epoch 62/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 48.7008 - val_loss: 5989.9209\n",
      "Epoch 63/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 47.9872 - val_loss: 5943.0674\n",
      "Epoch 64/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 47.6329 - val_loss: 6126.3711\n",
      "Epoch 65/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 47.3873 - val_loss: 5941.9351\n",
      "Epoch 66/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 46.4569 - val_loss: 6208.3657\n",
      "Epoch 67/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 46.2644 - val_loss: 6089.9443\n",
      "Epoch 68/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 46.4934 - val_loss: 5972.7979\n",
      "Epoch 69/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 45.8553 - val_loss: 5983.0063\n",
      "Epoch 70/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 44.6245 - val_loss: 5996.4800\n",
      "Epoch 71/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 44.8514 - val_loss: 5824.3916\n",
      "Epoch 72/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 43.7892 - val_loss: 5857.0811\n",
      "Epoch 73/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 45.1446 - val_loss: 5711.4756\n",
      "Epoch 74/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 43.0798 - val_loss: 5831.6094\n",
      "Epoch 75/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 42.8056 - val_loss: 6050.7407\n",
      "Epoch 76/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 42.8163 - val_loss: 6150.3276\n",
      "Epoch 77/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 42.8823 - val_loss: 5938.1323\n",
      "Epoch 78/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 42.7023 - val_loss: 5850.1304\n",
      "Epoch 79/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 42.1901 - val_loss: 5903.9004\n",
      "Epoch 80/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 42.3892 - val_loss: 6154.2603\n",
      "Epoch 81/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 40.8643 - val_loss: 6027.1523\n",
      "Epoch 82/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 40.8347 - val_loss: 5952.9028\n",
      "Epoch 83/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 41.3106 - val_loss: 5846.6465\n",
      "Epoch 84/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 39.5812 - val_loss: 6154.2480\n",
      "Epoch 85/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 39.7413 - val_loss: 5684.7744\n",
      "Epoch 86/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 39.4913 - val_loss: 5556.2290\n",
      "Epoch 87/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 42.1402 - val_loss: 5862.8677\n",
      "Epoch 88/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 39.0984 - val_loss: 5850.7690\n",
      "Epoch 89/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 40.8278 - val_loss: 5904.2856\n",
      "Epoch 90/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 40.2852 - val_loss: 5798.0762\n",
      "Epoch 91/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 38.2690 - val_loss: 5520.8726\n",
      "Epoch 92/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 38.4432 - val_loss: 5761.1011\n",
      "Epoch 93/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 38.3294 - val_loss: 5720.1987\n",
      "Epoch 94/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 37.6854 - val_loss: 5668.4268\n",
      "Epoch 95/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 40.3047 - val_loss: 5892.3115\n",
      "Epoch 96/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 37.4383 - val_loss: 5842.4492\n",
      "Epoch 97/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 37.0232 - val_loss: 5524.5845\n",
      "Epoch 98/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 38.4435 - val_loss: 5530.8184\n",
      "Epoch 99/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 39.0005 - val_loss: 5867.0845\n",
      "Epoch 100/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 38.8464 - val_loss: 5693.1260\n",
      "Epoch 101/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 37.3448 - val_loss: 5634.5713\n",
      "Epoch 102/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 36.4629 - val_loss: 5462.0874\n",
      "Epoch 103/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 37.0805 - val_loss: 5782.0015\n",
      "Epoch 104/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 36.1327 - val_loss: 5368.1460\n",
      "Epoch 105/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 36.8520 - val_loss: 5678.0845\n",
      "Epoch 106/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.7310 - val_loss: 5622.5845\n",
      "Epoch 107/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 35.9678 - val_loss: 5725.2314\n",
      "Epoch 108/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 39.5743 - val_loss: 5551.3291\n",
      "Epoch 109/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 36.7090 - val_loss: 6009.3984\n",
      "Epoch 110/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.9420 - val_loss: 5714.5059\n",
      "Epoch 111/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.6093 - val_loss: 5721.3047\n",
      "Epoch 112/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.4339 - val_loss: 5662.7642\n",
      "Epoch 113/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 35.7874 - val_loss: 5496.1240\n",
      "Epoch 114/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.8555 - val_loss: 5860.3535\n",
      "Epoch 115/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.8456 - val_loss: 5347.5942\n",
      "Epoch 116/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 35.6222 - val_loss: 5682.6431\n",
      "Epoch 117/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 34.7427 - val_loss: 5547.8003\n",
      "Epoch 118/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.7763 - val_loss: 5791.6309\n",
      "Epoch 119/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.0622 - val_loss: 5781.9287\n",
      "Epoch 120/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 34.5648 - val_loss: 5735.0420\n",
      "Epoch 121/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.9602 - val_loss: 5595.8989\n",
      "Epoch 122/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 34.2783 - val_loss: 5555.7002\n",
      "Epoch 123/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.7372 - val_loss: 5662.8408\n",
      "Epoch 124/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.1404 - val_loss: 5798.0229\n",
      "Epoch 125/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.0586 - val_loss: 5736.2847\n",
      "Epoch 126/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.9969 - val_loss: 5583.3999\n",
      "Epoch 127/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.9384 - val_loss: 5645.8672\n",
      "Epoch 128/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.8755 - val_loss: 5116.4834\n",
      "Epoch 129/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.6694 - val_loss: 5445.4780\n",
      "Epoch 130/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 33.6450 - val_loss: 5459.9673\n",
      "Epoch 131/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 33.4947 - val_loss: 5556.7422\n",
      "Epoch 132/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 33.0196 - val_loss: 5579.3125\n",
      "Epoch 133/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 34.7079 - val_loss: 5428.3989\n",
      "Epoch 134/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.0988 - val_loss: 5199.3115\n",
      "Epoch 135/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.5583 - val_loss: 5543.5776\n",
      "Epoch 136/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.7411 - val_loss: 5638.7778\n",
      "Epoch 137/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.2889 - val_loss: 5394.5635\n",
      "Epoch 138/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.9661 - val_loss: 5432.1323\n",
      "Epoch 139/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.9270 - val_loss: 5228.6211\n",
      "Epoch 140/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.6714 - val_loss: 5368.0757\n",
      "Epoch 141/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 40.4667 - val_loss: 5508.7036\n",
      "Epoch 142/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.4662 - val_loss: 5486.2812\n",
      "Epoch 143/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.9056 - val_loss: 5548.1021\n",
      "Epoch 144/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 35.7167 - val_loss: 5736.4019\n",
      "Epoch 145/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 35.1713 - val_loss: 5164.7793\n",
      "Epoch 146/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 36.4294 - val_loss: 5595.4404\n",
      "Epoch 147/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.9395 - val_loss: 5346.6030\n",
      "Epoch 148/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.8668 - val_loss: 5624.0625\n",
      "Epoch 149/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.5497 - val_loss: 5393.9038\n",
      "Epoch 150/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.6540 - val_loss: 5293.6963\n",
      "Epoch 151/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.8194 - val_loss: 5382.1777\n",
      "Epoch 152/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.6502 - val_loss: 5503.8389\n",
      "Epoch 153/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.6484 - val_loss: 5543.7881\n",
      "Epoch 154/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.7373 - val_loss: 5267.9595\n",
      "Epoch 155/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.1907 - val_loss: 5637.1694\n",
      "Epoch 156/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.3284 - val_loss: 5708.0728\n",
      "Epoch 157/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 37.1155 - val_loss: 5394.5830\n",
      "Epoch 158/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.1456 - val_loss: 5704.1343\n",
      "Epoch 159/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.2300 - val_loss: 5191.1279\n",
      "Epoch 160/400\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 32.9124 - val_loss: 5615.0605\n",
      "Epoch 161/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.1525 - val_loss: 5602.1416\n",
      "Epoch 162/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 34.3524 - val_loss: 5243.4517\n",
      "Epoch 163/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.0540 - val_loss: 5281.3291\n",
      "Epoch 164/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.5375 - val_loss: 5599.6426\n",
      "Epoch 165/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 36.4452 - val_loss: 5178.1226\n",
      "Epoch 166/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.9579 - val_loss: 5362.0884\n",
      "Epoch 167/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.9018 - val_loss: 5440.5439\n",
      "Epoch 168/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.7577 - val_loss: 5361.1221\n",
      "Epoch 169/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.9645 - val_loss: 5381.3799\n",
      "Epoch 170/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.1188 - val_loss: 5320.3735\n",
      "Epoch 171/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.2540 - val_loss: 5182.9243\n",
      "Epoch 172/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.8549 - val_loss: 5368.9175\n",
      "Epoch 173/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.2483 - val_loss: 5369.7583\n",
      "Epoch 174/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.5937 - val_loss: 5427.7417\n",
      "Epoch 175/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.4107 - val_loss: 5258.4438\n",
      "Epoch 176/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.7127 - val_loss: 5034.5552\n",
      "Epoch 177/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 33.2022 - val_loss: 5399.5210\n",
      "Epoch 178/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.6704 - val_loss: 5183.4102\n",
      "Epoch 179/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.9583 - val_loss: 5193.9595\n",
      "Epoch 180/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.8763 - val_loss: 5030.9771\n",
      "Epoch 181/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.7811 - val_loss: 5305.9365\n",
      "Epoch 182/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.2938 - val_loss: 5223.5708\n",
      "Epoch 183/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.4468 - val_loss: 5287.4624\n",
      "Epoch 184/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.2631 - val_loss: 4946.3696\n",
      "Epoch 185/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.8148 - val_loss: 4964.3784\n",
      "Epoch 186/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.3165 - val_loss: 5515.6060\n",
      "Epoch 187/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.2755 - val_loss: 4907.2314\n",
      "Epoch 188/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.4473 - val_loss: 5332.1738\n",
      "Epoch 189/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.0194 - val_loss: 5101.5181\n",
      "Epoch 190/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.6633 - val_loss: 5213.6758\n",
      "Epoch 191/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.0890 - val_loss: 5070.6143\n",
      "Epoch 192/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.5266 - val_loss: 4935.0933\n",
      "Epoch 193/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.1582 - val_loss: 4995.3706\n",
      "Epoch 194/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.9255 - val_loss: 5011.9595\n",
      "Epoch 195/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.0028 - val_loss: 5295.9717\n",
      "Epoch 196/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 37.7467 - val_loss: 5064.6694\n",
      "Epoch 197/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.5395 - val_loss: 4842.1743\n",
      "Epoch 198/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.7842 - val_loss: 4850.4199\n",
      "Epoch 199/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.8557 - val_loss: 5128.7397\n",
      "Epoch 200/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.7928 - val_loss: 5039.9395\n",
      "Epoch 201/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.7627 - val_loss: 5044.6709\n",
      "Epoch 202/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.3902 - val_loss: 5116.2363\n",
      "Epoch 203/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.2153 - val_loss: 5062.7241\n",
      "Epoch 204/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.1205 - val_loss: 4874.0210\n",
      "Epoch 205/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.9402 - val_loss: 4818.0713\n",
      "Epoch 206/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.8459 - val_loss: 4800.7378\n",
      "Epoch 207/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.7735 - val_loss: 4910.0225\n",
      "Epoch 208/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.5231 - val_loss: 4960.4458\n",
      "Epoch 209/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.3985 - val_loss: 4867.9663\n",
      "Epoch 210/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.3464 - val_loss: 5117.3130\n",
      "Epoch 211/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.4647 - val_loss: 5080.4194\n",
      "Epoch 212/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.8308 - val_loss: 4854.6064\n",
      "Epoch 213/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.5566 - val_loss: 4929.3223\n",
      "Epoch 214/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.2789 - val_loss: 5061.5420\n",
      "Epoch 215/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.5192 - val_loss: 4954.8936\n",
      "Epoch 216/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.8191 - val_loss: 5192.1372\n",
      "Epoch 217/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.4044 - val_loss: 4606.6611\n",
      "Epoch 218/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.0860 - val_loss: 4819.1089\n",
      "Epoch 219/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.4570 - val_loss: 5124.6299\n",
      "Epoch 220/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 34.9512 - val_loss: 5058.2812\n",
      "Epoch 221/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.8833 - val_loss: 5307.3442\n",
      "Epoch 222/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 36.9356 - val_loss: 4774.0986\n",
      "Epoch 223/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.6779 - val_loss: 5005.8916\n",
      "Epoch 224/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.1835 - val_loss: 5194.5103\n",
      "Epoch 225/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.3957 - val_loss: 4935.2651\n",
      "Epoch 226/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.1615 - val_loss: 5375.8862\n",
      "Epoch 227/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.6841 - val_loss: 4748.1860\n",
      "Epoch 228/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.1069 - val_loss: 4903.4736\n",
      "Epoch 229/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.0785 - val_loss: 4812.3696\n",
      "Epoch 230/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 32.4935 - val_loss: 5155.4976\n",
      "Epoch 231/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.2170 - val_loss: 4870.9761\n",
      "Epoch 232/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.9877 - val_loss: 5102.7251\n",
      "Epoch 233/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.8946 - val_loss: 4647.5229\n",
      "Epoch 234/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.6091 - val_loss: 4890.4536\n",
      "Epoch 235/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.9431 - val_loss: 4913.7305\n",
      "Epoch 236/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.3473 - val_loss: 4749.9395\n",
      "Epoch 237/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.4807 - val_loss: 4924.4116\n",
      "Epoch 238/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.5742 - val_loss: 4876.9849\n",
      "Epoch 239/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.8331 - val_loss: 5261.1504\n",
      "Epoch 240/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.6318 - val_loss: 4698.2271\n",
      "Epoch 241/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.0778 - val_loss: 4771.9814\n",
      "Epoch 242/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.7950 - val_loss: 4583.4414\n",
      "Epoch 243/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.5412 - val_loss: 4864.6230\n",
      "Epoch 244/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.2528 - val_loss: 5023.6655\n",
      "Epoch 245/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.1316 - val_loss: 5180.9507\n",
      "Epoch 246/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.8830 - val_loss: 4710.6670\n",
      "Epoch 247/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.2993 - val_loss: 4889.7964\n",
      "Epoch 248/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.0006 - val_loss: 4998.4600\n",
      "Epoch 249/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.7961 - val_loss: 4941.7485\n",
      "Epoch 250/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.8494 - val_loss: 4924.6753\n",
      "Epoch 251/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.3549 - val_loss: 5049.4058\n",
      "Epoch 252/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.1869 - val_loss: 4793.7886\n",
      "Epoch 253/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.6211 - val_loss: 4842.5894\n",
      "Epoch 254/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.0723 - val_loss: 4912.3740\n",
      "Epoch 255/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 36.0050 - val_loss: 4687.2036\n",
      "Epoch 256/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.6172 - val_loss: 4694.7090\n",
      "Epoch 257/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.3019 - val_loss: 4708.8008\n",
      "Epoch 258/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.8225 - val_loss: 4763.1943\n",
      "Epoch 259/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.5615 - val_loss: 4820.1611\n",
      "Epoch 260/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.5443 - val_loss: 4826.1831\n",
      "Epoch 261/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.9117 - val_loss: 4877.6079\n",
      "Epoch 262/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.3737 - val_loss: 4863.4790\n",
      "Epoch 263/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.3924 - val_loss: 4570.4727\n",
      "Epoch 264/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.4482 - val_loss: 4786.0298\n",
      "Epoch 265/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.3742 - val_loss: 5082.6240\n",
      "Epoch 266/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.1696 - val_loss: 4761.8711\n",
      "Epoch 267/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.3733 - val_loss: 4773.0425\n",
      "Epoch 268/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.9900 - val_loss: 4766.9419\n",
      "Epoch 269/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.9013 - val_loss: 4645.5190\n",
      "Epoch 270/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.5201 - val_loss: 4726.5044\n",
      "Epoch 271/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.2835 - val_loss: 4845.5825\n",
      "Epoch 272/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.1758 - val_loss: 4755.8550\n",
      "Epoch 273/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.6959 - val_loss: 4584.5098\n",
      "Epoch 274/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.9405 - val_loss: 4641.1562\n",
      "Epoch 275/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.8666 - val_loss: 4885.6704\n",
      "Epoch 276/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.3523 - val_loss: 4800.3018\n",
      "Epoch 277/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.6096 - val_loss: 4871.3267\n",
      "Epoch 278/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.9918 - val_loss: 4721.0420\n",
      "Epoch 279/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.3096 - val_loss: 4876.9326\n",
      "Epoch 280/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.4022 - val_loss: 5012.8838\n",
      "Epoch 281/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 35.5664 - val_loss: 4655.5840\n",
      "Epoch 282/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.3251 - val_loss: 4641.8994\n",
      "Epoch 283/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.8556 - val_loss: 4631.8271\n",
      "Epoch 284/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.8305 - val_loss: 5024.1821\n",
      "Epoch 285/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 33.6247 - val_loss: 4199.2026\n",
      "Epoch 286/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.7633 - val_loss: 4738.7241\n",
      "Epoch 287/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.3359 - val_loss: 4795.6699\n",
      "Epoch 288/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.8221 - val_loss: 4754.5371\n",
      "Epoch 289/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.2641 - val_loss: 4677.9990\n",
      "Epoch 290/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.5765 - val_loss: 4624.6235\n",
      "Epoch 291/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.1601 - val_loss: 4462.1782\n",
      "Epoch 292/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.7723 - val_loss: 4613.5874\n",
      "Epoch 293/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.7507 - val_loss: 4653.3403\n",
      "Epoch 294/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.6947 - val_loss: 4644.5308\n",
      "Epoch 295/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.5748 - val_loss: 4661.9844\n",
      "Epoch 296/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.5469 - val_loss: 4778.4834\n",
      "Epoch 297/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.8351 - val_loss: 4651.8354\n",
      "Epoch 298/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.5202 - val_loss: 4832.7769\n",
      "Epoch 299/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.1915 - val_loss: 5045.8677\n",
      "Epoch 300/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 36.0420 - val_loss: 4650.9131\n",
      "Epoch 301/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.1358 - val_loss: 4488.9551\n",
      "Epoch 302/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.4263 - val_loss: 4574.1147\n",
      "Epoch 303/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.9151 - val_loss: 4720.1133\n",
      "Epoch 304/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.1439 - val_loss: 4723.2891\n",
      "Epoch 305/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.7462 - val_loss: 4841.4956\n",
      "Epoch 306/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.3829 - val_loss: 4357.0098\n",
      "Epoch 307/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.4352 - val_loss: 4529.8091\n",
      "Epoch 308/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.1739 - val_loss: 4541.9365\n",
      "Epoch 309/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.5308 - val_loss: 4283.1909\n",
      "Epoch 310/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.2316 - val_loss: 4650.6440\n",
      "Epoch 311/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.5385 - val_loss: 4626.3379\n",
      "Epoch 312/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.6361 - val_loss: 4327.0552\n",
      "Epoch 313/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.2232 - val_loss: 4480.6504\n",
      "Epoch 314/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.3700 - val_loss: 4545.2832\n",
      "Epoch 315/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.8317 - val_loss: 5085.8062\n",
      "Epoch 316/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 34.4749 - val_loss: 4437.1836\n",
      "Epoch 317/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.7355 - val_loss: 4257.2715\n",
      "Epoch 318/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.1293 - val_loss: 4160.8838\n",
      "Epoch 319/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.4036 - val_loss: 4581.4780\n",
      "Epoch 320/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.1652 - val_loss: 4593.4536\n",
      "Epoch 321/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.8463 - val_loss: 4511.9961\n",
      "Epoch 322/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.3737 - val_loss: 4371.7915\n",
      "Epoch 323/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.8280 - val_loss: 4302.9438\n",
      "Epoch 324/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.0384 - val_loss: 4278.6343\n",
      "Epoch 325/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.5806 - val_loss: 4315.2822\n",
      "Epoch 326/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.3806 - val_loss: 4271.7017\n",
      "Epoch 327/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.2731 - val_loss: 4125.5156\n",
      "Epoch 328/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.1099 - val_loss: 4399.0762\n",
      "Epoch 329/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.5358 - val_loss: 4134.1230\n",
      "Epoch 330/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.2982 - val_loss: 4664.2139\n",
      "Epoch 331/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.3453 - val_loss: 4371.5454\n",
      "Epoch 332/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 30.3896 - val_loss: 4458.7686\n",
      "Epoch 333/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.7356 - val_loss: 4499.2388\n",
      "Epoch 334/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.7063 - val_loss: 4554.4858\n",
      "Epoch 335/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.2284 - val_loss: 4405.8306\n",
      "Epoch 336/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.2858 - val_loss: 4393.3608\n",
      "Epoch 337/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.2209 - val_loss: 4264.7427\n",
      "Epoch 338/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.3940 - val_loss: 4654.4487\n",
      "Epoch 339/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.0331 - val_loss: 4284.8433\n",
      "Epoch 340/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.7502 - val_loss: 4137.7983\n",
      "Epoch 341/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.3119 - val_loss: 4187.7632\n",
      "Epoch 342/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.4858 - val_loss: 4364.9810\n",
      "Epoch 343/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.4950 - val_loss: 4424.1782\n",
      "Epoch 344/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.2949 - val_loss: 4278.0679\n",
      "Epoch 345/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.6238 - val_loss: 4463.2886\n",
      "Epoch 346/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.7575 - val_loss: 4307.9233\n",
      "Epoch 347/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.6621 - val_loss: 3905.8491\n",
      "Epoch 348/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.0421 - val_loss: 4328.0566\n",
      "Epoch 349/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.0162 - val_loss: 4219.1133\n",
      "Epoch 350/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.3972 - val_loss: 4311.6768\n",
      "Epoch 351/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.9807 - val_loss: 4140.2510\n",
      "Epoch 352/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.8356 - val_loss: 4455.1743\n",
      "Epoch 353/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 32.6327 - val_loss: 4325.5737\n",
      "Epoch 354/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.1495 - val_loss: 4133.7993\n",
      "Epoch 355/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.7286 - val_loss: 4149.0879\n",
      "Epoch 356/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.6594 - val_loss: 4342.5732\n",
      "Epoch 357/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.4660 - val_loss: 4460.5625\n",
      "Epoch 358/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.7646 - val_loss: 4319.3740\n",
      "Epoch 359/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.6085 - val_loss: 4311.4346\n",
      "Epoch 360/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.0062 - val_loss: 4368.9946\n",
      "Epoch 361/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.2497 - val_loss: 4232.4600\n",
      "Epoch 362/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.0995 - val_loss: 4077.8179\n",
      "Epoch 363/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.7277 - val_loss: 4398.3857\n",
      "Epoch 364/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.8066 - val_loss: 4254.2925\n",
      "Epoch 365/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 31.1410 - val_loss: 4296.1050\n",
      "Epoch 366/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 27.7498 - val_loss: 4182.3730\n",
      "Epoch 367/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.0135 - val_loss: 4474.0488\n",
      "Epoch 368/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.2949 - val_loss: 4109.7529\n",
      "Epoch 369/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.7323 - val_loss: 4269.1230\n",
      "Epoch 370/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 27.2174 - val_loss: 4264.9639\n",
      "Epoch 371/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.6215 - val_loss: 4235.3848\n",
      "Epoch 372/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.7570 - val_loss: 4034.8159\n",
      "Epoch 373/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 27.5410 - val_loss: 4240.1299\n",
      "Epoch 374/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.1722 - val_loss: 3935.1570\n",
      "Epoch 375/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.8761 - val_loss: 4007.3042\n",
      "Epoch 376/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 29.8613 - val_loss: 4002.7544\n",
      "Epoch 377/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.4963 - val_loss: 3951.0835\n",
      "Epoch 378/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.8688 - val_loss: 4114.3364\n",
      "Epoch 379/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.3113 - val_loss: 4031.4402\n",
      "Epoch 380/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 30.9088 - val_loss: 4021.2944\n",
      "Epoch 381/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.3736 - val_loss: 4117.1230\n",
      "Epoch 382/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.0715 - val_loss: 4053.9529\n",
      "Epoch 383/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 27.5986 - val_loss: 4227.4077\n",
      "Epoch 384/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.5498 - val_loss: 4106.7778\n",
      "Epoch 385/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.2725 - val_loss: 3902.1350\n",
      "Epoch 386/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 28.1759 - val_loss: 4252.2896\n",
      "Epoch 387/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 27.5031 - val_loss: 3989.6143\n",
      "Epoch 388/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.9118 - val_loss: 4261.4014\n",
      "Epoch 389/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.2097 - val_loss: 4018.4597\n",
      "Epoch 390/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.2244 - val_loss: 4102.8125\n",
      "Epoch 391/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.4987 - val_loss: 4135.3442\n",
      "Epoch 392/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.0167 - val_loss: 4111.3936\n",
      "Epoch 393/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.5900 - val_loss: 4315.4375\n",
      "Epoch 394/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 27.6398 - val_loss: 3893.4077\n",
      "Epoch 395/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 29.2706 - val_loss: 3760.4189\n",
      "Epoch 396/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.4308 - val_loss: 4016.5452\n",
      "Epoch 397/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.7796 - val_loss: 4083.6130\n",
      "Epoch 398/400\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 28.1766 - val_loss: 4215.7378\n",
      "Epoch 399/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.8723 - val_loss: 3671.6797\n",
      "Epoch 400/400\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 27.8083 - val_loss: 3876.4082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f3e744e88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('SPY500_stock_price_multiple_variables_1_10.xlsx', sheet_name='Data')\n",
    "# Split data into features and target variable\n",
    "X = data[['Date_Num','GDP','UNRATE','CPIAUCSL','FEDFUNDS']]\n",
    "y = data['Close']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=400, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd5c3b7c-cc8d-451c-8278-459fdd5433c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[378.5505]]\n"
     ]
    }
   ],
   "source": [
    "reference_date = dt.datetime(1993, 1, 25)  # Set the reference date to Jan 25, 1993\n",
    "Date_r = (dt.datetime(2023, 1, 1) - reference_date).days  # Calculate the number of days since the reference date\n",
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({'Date_Num': [Date_r],\n",
    "                      'GDP': [20187], \n",
    "                      'UNRATE': [3.5],\n",
    "                      'CPIAUCSL': [6.44], \n",
    "                      'FEDFUNDS': [4.10]})\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "prediction = model.predict(new_data_scaled)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "772b03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "model.save(\"trained_spy_prediction_06.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b5fa438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model to a new object\n",
    "saved_model = tf.keras.models.load_model('trained_spy_prediction_06.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a4f9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = pd.read_excel('SPY500_stock_price_multiple_variables_1_10.xlsx', sheet_name='EI_Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7442b12-3946-4a9b-88c6-eda5a0e7e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "reference_date = dt.datetime(1993, 1, 25)  # Set the reference date to Jan 25, 1993\n",
    "prediction_list = []\n",
    "\n",
    "for _, row in predicted_data.iterrows():\n",
    "    Date_r = (row['Date'] - reference_date).days  # Calculate the number of days since the reference date\n",
    "    # Make predictions on new data\n",
    "    new_data = pd.DataFrame({'Date_Num': [Date_r],\n",
    "                        'GDP': [row.GDP_Est], \n",
    "                        'UNRATE': [row.UR_Pred],\n",
    "                        'CPIAUCSL': [row.CPI_Est], \n",
    "                        'FEDFUNDS': [row.IR_Est]})\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    prediction = saved_model.predict(new_data_scaled)\n",
    "    prediction_list.append(float(prediction[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c543d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data['Prediction'] = prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99b7c4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Date_Text</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>GDP_Est</th>\n",
       "      <th>CPI_Est</th>\n",
       "      <th>IR_Est</th>\n",
       "      <th>UR_Pred</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>01/02/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q1</td>\n",
       "      <td>2023M1</td>\n",
       "      <td>20187.495000</td>\n",
       "      <td>8.05</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.865880</td>\n",
       "      <td>394.453979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>01/09/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q1</td>\n",
       "      <td>2023M1</td>\n",
       "      <td>20217.458558</td>\n",
       "      <td>8.05</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.865880</td>\n",
       "      <td>394.980133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>01/16/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q1</td>\n",
       "      <td>2023M1</td>\n",
       "      <td>20247.422115</td>\n",
       "      <td>8.05</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.865880</td>\n",
       "      <td>395.506378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>01/23/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q1</td>\n",
       "      <td>2023M1</td>\n",
       "      <td>20277.385673</td>\n",
       "      <td>8.05</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.865880</td>\n",
       "      <td>396.032501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>01/30/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q1</td>\n",
       "      <td>2023M1</td>\n",
       "      <td>20307.349231</td>\n",
       "      <td>8.05</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.865880</td>\n",
       "      <td>396.558685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>12/02/2024</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024M12</td>\n",
       "      <td>22063.129231</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.712981</td>\n",
       "      <td>360.446808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>12/09/2024</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024M12</td>\n",
       "      <td>22069.744423</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.712981</td>\n",
       "      <td>360.733307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2024-12-16</td>\n",
       "      <td>12/16/2024</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024M12</td>\n",
       "      <td>22076.359615</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.712981</td>\n",
       "      <td>361.019836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2024-12-23</td>\n",
       "      <td>12/23/2024</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024M12</td>\n",
       "      <td>22082.974808</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.712981</td>\n",
       "      <td>361.306305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>12/30/2024</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024M12</td>\n",
       "      <td>22089.590000</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.712981</td>\n",
       "      <td>361.592834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   Date_Text  Month  Day  Year Quarter YearMonth       GDP_Est  \\\n",
       "0   2023-01-02  01/02/2023      1    2  2023  2023Q1    2023M1  20187.495000   \n",
       "1   2023-01-09  01/09/2023      1    9  2023  2023Q1    2023M1  20217.458558   \n",
       "2   2023-01-16  01/16/2023      1   16  2023  2023Q1    2023M1  20247.422115   \n",
       "3   2023-01-23  01/23/2023      1   23  2023  2023Q1    2023M1  20277.385673   \n",
       "4   2023-01-30  01/30/2023      1   30  2023  2023Q1    2023M1  20307.349231   \n",
       "..         ...         ...    ...  ...   ...     ...       ...           ...   \n",
       "100 2024-12-02  12/02/2024     12    2  2024  2024Q4   2024M12  22063.129231   \n",
       "101 2024-12-09  12/09/2024     12    9  2024  2024Q4   2024M12  22069.744423   \n",
       "102 2024-12-16  12/16/2024     12   16  2024  2024Q4   2024M12  22076.359615   \n",
       "103 2024-12-23  12/23/2024     12   23  2024  2024Q4   2024M12  22082.974808   \n",
       "104 2024-12-30  12/30/2024     12   30  2024  2024Q4   2024M12  22089.590000   \n",
       "\n",
       "     CPI_Est  IR_Est   UR_Pred  Prediction  \n",
       "0       8.05     5.2  3.865880  394.453979  \n",
       "1       8.05     5.2  3.865880  394.980133  \n",
       "2       8.05     5.2  3.865880  395.506378  \n",
       "3       8.05     5.2  3.865880  396.032501  \n",
       "4       8.05     5.2  3.865880  396.558685  \n",
       "..       ...     ...       ...         ...  \n",
       "100     2.59     4.1  4.712981  360.446808  \n",
       "101     2.59     4.1  4.712981  360.733307  \n",
       "102     2.59     4.1  4.712981  361.019836  \n",
       "103     2.59     4.1  4.712981  361.306305  \n",
       "104     2.59     4.1  4.712981  361.592834  \n",
       "\n",
       "[105 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d192c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data.to_excel(\"predicted_data.xlsx\", sheet_name = 'Sheet1', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
